[
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "LuciusOperations",
    "section": "",
    "text": "The glue that holds the Compass stack together\n\n\n\nThis repo is a toolbox for the maintenance of the Lucius stack. The main goal is to make life easier initializing/running/checking the APIs that are part of the stack: LuciusAPI and LuciusProcessing. We might add functionality for Sourire (and perhaps even Brutus) later as well.\nLuciusAPI and LuciusProcessing are two REST APIs that are both endpoints defined using the Spark-Jobserver project and that expose complementary functionality:\n\n\nLuciusProcessing deals with preparing source data into a format that can be initialized for LuciusAPI.\nLuciusProcessing only exposes 2 endpoints: a process endpoint for processing the data from input to LuciusAPI-ready output and a check endpoint for retrieving information about source and (pre-computed) output.\n\n\n\nLuciusAPI is the engine for the LuciusWeb web frontend. It defines endpoints for all the queries and computations that need to be performed in the application. A Spark context is running 24x7 and LuciusAPI acts as the interface to that Spark context.\nLuciusAPI contains many more endpoints for every kind of query of computation that needs to be available to the frontend. The concrete implementation of these endpoints is provided by the [LuciusCore] library: Zhang correlation calculation, histogram, …\n\n\n\n\nConnecting to those APIs is not hard: in principle one sends a configuration object to the API and one gets a JSON object back. It does requires a very strict format for input and parameters and is cumbersome to write though.\nIn order to aid in connecting to the APIs and as such also perform basic processing and initialization tasks, we developed the LuciusOperations toolbox.\n\n\n\nThe short version is to fetch the LuciusOperations repository, make sure you have Java 8 or higher installed and run bin/build.sh. After this, the tools for LuciusProcessing and LuciusAPI are respectively under utils/processing and utils/api:\nutils\n├── api\n│   ├── check\n│   ├── create_context\n│   ├── fetch_jar\n│   ├── initialize\n│   ├── remove_context\n│   └── upload_jar\n└── processing\n├── check\n├── create_context\n├── fetch_jar\n├── process\n├── remove_context\n└── upload_jar\nEvery tool in the toolbox is a (Viash) standalone script that contains it’s own help, i.e.:\n❯ utils/processing/check -h\ncheck dev\n\nArguments:\n--endpoint\ntype: string\ndefault: http://localhost:8090\nThe endpoint (URL) to connect to\n\n...\nPlease refer to the installation instructions for more information about what is happening behind the scenes.\n\n\n\nA typical workflow would look like this:\n\nEnsure the spark-jobserver is running\nMake sure the JAR files for LuciusAPI and LuciusProcessing are available in a local directory, preferably one next to the other. Those JAR files are typically built using a CI pipeline, but can be fetched from the github repository as well.\nUpdate the _viash.yaml configuration file for your environment.\nrun bin/build.sh again, as this will build the different tools with the correct defaults as provided in the _viash.yaml config file.\nRun the following commands:\nutils/processing/upload_jar        # Upload both JAR files\nutils/api/upload_jar               \nutils/processing/create_context    # create the context\nutils/processing/process           # start the processing job\nutils/processing/check             # verify if output is written\nutils/api/initialize               # initialize Spark job\nutils/api/check                    # after some time, check\n\n\n\n\nThe following are required in order to run the components from the toolbox:\n\nwget\nbash\ncurl\n\nOne day, we might allow HTTPie to be used for a more user friendly way of calling the endpoints."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation Instructions",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "usage.html",
    "href": "usage.html",
    "title": "Usage",
    "section": "",
    "text": "TODO"
  }
]